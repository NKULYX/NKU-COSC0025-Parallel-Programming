- [x] 代码实现
- [x] 代码优化：循环展开
- [ ] 性能测试
  - [x] 规模测试：不同大小规模下的时间
    - [x] 绘制走势，对比放一张图
    - [x] 找到趋势转折点，让cache大小不足
      - [x] 利用工具测试该点前后的命中率
  - [ ] 对比平台
    - [ ] x86和arm Linux下
  - [ ] 编译优化力度：arm + Linux 下
    - [ ] 不同编译优化力度下的走势

# 问题重述

## 体系结构相关实验分析——cache优化

计算给定n*n矩阵的每一列和给定向量的内积，考虑两种算法设计思路：

1. 逐列访问元素的平凡算法
2. cache的优化算法

## 体系结构相关实验分析——超标量优化

计算n个数的和，考虑两种算法的设计思路

1. 逐个累加的平凡算法
2. 超标量优化算法，如最简单的两路链式累加，或两两相加后中间结果再两两相加的递归算法

# 实验环境

## ARM架构

|   参数   |  数值  |
| :------: | :----: |
| CPU主频  | 2.6GHz |
| L1 cache |  64K   |
| L2 cache |  521K  |
| L3 cache |  48MB  |

## x86架构

|   参数   |         数值         |
| :------: | :------------------: |
| CPU型号  | Intel Core i7-11800H |
| CPU主频  |        2.3GHz        |
| L1 cache |         48K          |
| L2 cache |        1.25MB        |
| L3 cache |         24MB         |

# 实验设计及分析

## cache优化

针对给定的问题，由于矩阵在内存中存储时按照行有限的顺序存储的，也就是说，在内存中的矩阵是按行紧密排列的。因此，对于原始朴素的逐列访问算法来说，CPU会一次读入连续的一段数据到缓存中，其中可能只包含需要计算一个元素，因此当计算该列的第二个元素的时候，CPU又需要到更低的缓存或内存中去读取所需要的元素，而访存的时间相较于运算来说，开销是很大的，这会在很大程度上降低程序运行的效率。

因此我们考虑改进算法，采用逐列访问的cache优化算法，即充分利用每次读入的数据，将当前读入的缓存中的一行数据全部进行计算，然后累加到结果数组的对应位置，虽然在这个过程中并没有能够直接计算出结果，但是极大利用了cache中的缓存数据，减少去内存中寻找数据的访存时间。

同时，为了能够降低循环访问过程中，条件判断，指令跳转等额外开销，我们对于逐列访问的算法进行了进一步优化，采用循环展开的方法，在一次循环中，同时计算十个位置的值，可以利用多条流水线同时作业，发挥CPU超标量计算的性能。

为此，我们分别设计了三种算法，并在ARM架构的华为云鲲鹏服务器上进行测试

![p1](E:\学习资料\大二\并行程序设计\Experiment\Lab1\p1.jpg)

根据测试数据我们可以看出，在N<100的规模下，逐行或逐列的访问方式在效率上差别不大，但采用循环展开的优化算法能够取得较大的性能提升，而当N<1000时，逐列访问要比逐行访问的增长速度慢，但在N<1000的规模下，三种方法的增长趋势还是基本相同的。当N>3000之后，逐行访问的增长速度要明显超越了逐列访问的方法，证明此时cache优化起到了显著作用。



为了证明在N>3000之后，cache起到了显著作用，我们利用perf方法来获取了程序运行过程中的L1 cache命中率。通过测试，在N<1000时，无论是逐列访问的方法还是逐行访问的方法，由于问题规模比较小，绝大部分数据都能在一级缓存命中，L1 cache未命中率，逐行访问的方法在0.5%-1%之间，而逐列访问的方法在0.1%左右。而当问题规模逐渐增大，由于L1 cache的大小有限，不能将所有的数据全部读入，因此逐行访问的方式的L1 cache命中率开始显著下降，而逐列访问的cache优化方法并没有显著的提升，这也是导致两种方法增长速度产生显著差异的重要原因。

对于循环展开方法对逐列访问方式的优化，由于循环展开可以在一个循环周期内利用多条流水线并行执行相同指令，因此能够在一定程度上优化代码运行效率。这一点通过比较两种方法的CPI也能够得到印证。

| optimize | optimize+unroll |
| :------: | :-------------: |
|  0.4975  |     0.4761      |

## 超标量优化

